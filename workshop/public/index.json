[
{
	"uri": "/",
	"title": "DevSecOps on AWS",
	"tags": [],
	"description": "",
	"content": "In this workshop we will build a pipeline for a sample WordPress site in a stack. We will explore how to validate, lint and test templates, and dive deeper in tools that help you enforce compliance and network analysis, together with your development pipeline, for a full DevSecOps CI/CD.\n"
},
{
	"uri": "/introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Transitioning to DevOps requires a change in culture and mindset. At its simplest, DevOps is about removing the barriers between traditionally siloed teams; development, operations and security. In some organizations, there may not even be separate development, operations and security teams; engineers may do both. With DevOps, the two disciplines work together to optimize both the productivity of developers and the reliability of operations.\nThe alignment of development and operations teams has made it possible to build customized software and business functions quicker than before, but security teams continue to be left out of the DevOps conversation. In a lot of organizations, security is still viewed as or operates as roadblocks to rapid development or operational implementations, slowing down production code pushes. As a result, security processes are ignored or missed as the DevOps teams view them as a road block toward their pending success. As part of your organization strategy towards a security, automated and orchestrated cloud deployment and operations and you will need to unite the DevOps and SecOps teams in an effort to fully support and operationalize your organizations cloud operations\nSkills Security specialist\n Face a rapidly changing technology landscape Prepared to dive deeper in AWS and take the Security Certification Specialty and learning path How would codified security look like in an envirnoment you own? Start with Python. Lambda, config, other SDKs  Everyone\n Get in the mindset!  Outcome Security teams tend to be an order of magnitude smaller than developer teams. The goal of DevSecOps is to go from security being the \u0026ldquo;department of no\u0026rdquo; to security being an enabler.\nBy the end of this workshop, we want you to have some ideas on how you can accelerate your security teams to keep up with the development team. We want you to be able to react and detect vulnerabilities faster, using event driven architectures.\n  Security and Compliance is a shared responsibility between AWS and the customer. This differentiation of responsibility is commonly referred to as Security “of” the Cloud versus Security “in” the Cloud.   "
},
{
	"uri": "/clone.html",
	"title": "Clone Repository",
	"tags": [],
	"description": "",
	"content": " Clone this repository. From your terminal application, execute the following command. This creates a directory named aws-devsecops-workshop in your current directory.  git clone https://github.com/aws-samples/aws-devsecops-workshop Create AWS CodeCommit repository in your AWS account and set up AWS CLI. Name your repository wordpress-cfn. Alternatively, from your terminal application, execute the following command and note the cloneUrlHttp URL in the response from the CLI.  aws codecommit create-repository --repository-name wordpress-cfn --repository-description \u0026quot;This template installs WordPress with a local MySQL database for storage\u0026quot; Create the local git setup required to push code to CodeCommit repository and add a new remote. From your terminal application, within the wordpress-dfn directory, execute the following command:  git init \u0026amp;\u0026amp; git remote add AWSCodeCommit HTTP_CLONE_URL_FROM_STEP_2 Install git-secrets and ensure the git repository is scanned for secrets on each commit.  git secrets --install git secrets --register-aws  git-secrets scans commits, commit messages, and \u0026ndash;no-ff merges to prevent adding secrets into your git repositories. If a commit, commit message, or any commit in a \u0026ndash;no-ff merge history matches one of your configured prohibited regular expression patterns, then the commit is rejected.\n https://github.com/aws-samples/aws-devsecops-workshop/blob/master/wordpress/wordpress-single-instance.yaml\n "
},
{
	"uri": "/secrets.html",
	"title": "Store Secrets",
	"tags": [],
	"description": "",
	"content": "When using AWS CloudFormation templates to code your infrastructure, you should consider applying best practices to improve the maintainability of your code. Further, these best practices should be augmented by guidelines like those outlined for twelve-factor apps, which are targeted at optimizing applications for continuous deployment. Of these factors, you should note that you should strive for strict separation of configuration information from your code wherever possible, since configuration information will often vary across deployments, while code typically does not. Also, from a code and configuration perspective, you should strive to keep your development and production code as similar as possible because this will aid quick replication of any production issues or bugs.\nWith AWS CloudFormation, you have several options to avoid storing configuration as constants in your template code, which amounts in most cases to hardcoding runtime configuration details. Instead, you should take advantage of various options for using parameters. Further, you can elicit those parameters from users in the AWS Management Console, or from a separate runtime variable by using a CLI or API call, or by using a parameter file.\n# # This snippet of the template accesses stored parameters # for the database name and passwords. # A non-secure SSM Parameter for the DB name # A Secrets Manager Parameter for the master password # Parameters: DBName: Description: The WordPress database name Default: \u0026#34;{{resolve:ssm:dbName:1}}\u0026#34; Type: String DBPassword: Description: The WordPress database admin account password Default: \u0026#34;{{resolve:secretsmanager:dbPassword}}\u0026#34; Type: String In the console, initialise the parameters the Wordpress stack fetches from AWS Systems Manager Parameter Store and AWS Secrets Manager using your CLI.\naws ssm put-parameter --name dbName --type String --value \u0026#34;WordPressDB\u0026#34; aws ssm put-parameter --name dbUser --type String --value \u0026#34;DBuser\u0026#34; aws secretsmanager create-secret --name dbPassword --secret-string DBPassword aws secretsmanager create-secret --name dbRootPassword --secret-string DBRootPassword AWS Secrets Manager is a service to manage the lifecycle for the secrets used in your organization centrally including rotation, audit, and access control. Secrets Manager helps you meet your security and compliance requirements by enabling you to rotate secrets automatically. Secrets Manager offers built-in integration for MySQL, PostgreSQL, and Amazon Aurora on Amazon RDS that\u0026rsquo;s extensible to other types of secrets by customizing Lambda functions.\nAWS Systems Manager Parameter Store provides secure, hierarchical storage for configuration data management, which can include secrets. Data such as database strings, passwords, and license codes can be stored as parameter values. Values stored can be either plain text or encrypted data. You can then reference values by using the unique name specified when creating the parameter. You can reference Systems Manager parameters in your scripts and commands for configuration and automation workflows.\nGenerally speaking, if you only need simple store/retrieve functionality use AWS Systems Manager Parameter Store. If you wants extra functionality, such as lifecycle management and rotation, use AWS Secrets Manager.\n "
},
{
	"uri": "/launch.html",
	"title": "Launch Stacks",
	"tags": [],
	"description": "",
	"content": "Launch the CloudFormation template that creates the Pipeline in your account.\n\nExplain the pipeline better\n Lets dive into it. This CloudFormation templates builds a pipeline for a sample WordPress site in a stack. The pipeline is separated into four stages. Each stage must contain at least one action, which is a task the pipeline performs on your artifacts (your input). A stage organizes actions in a pipeline. CodePipeline must complete all actions in a stage before the stage processes new artifacts, for example, if you submitted new input to rerun the pipeline.\nThe pipeline that performs the following workflow:\n  The first stage of the pipeline retrieves a source artifact (an AWS CloudFormation template) from a repository. You\u0026rsquo;ll prepare an artifact that includes a sample WordPress template and upload it to an S3 bucket.\n  In the second stage, the pipeline performs a series of validation tests to the AWS CloudFormation template. These include cfn-validate-template, cfn_nag and taskcat, and then the pipeline continues to the next stage.\n  In the third stage, the pipeline creates a test stack and then waits for your approval. After you review the test stack, you can choose to continue with the original pipeline or create and submit another artifact to make changes. If you approve, this stage deletes the test stack, and then the pipeline continues to the next stage.\n  In the fourth stage, the pipeline creates a change set against a production stack, and then waits for your approval. In your initial run, you won\u0026rsquo;t have a production stack. The change set shows you all of the resources that AWS CloudFormation will create. If you approve, this stage executes the change set and builds your production stack.\n  Open DevSecOps-Wordpress on the CodePipeline console. It looks something like this:\nWhy did the stack failed to run? Click on the details button of the Package Export action, and link to the execution details to look at the build logs.\nOne of the validation tests failed. The output logs the following message:\nAn error occurred (ValidationError) when calling the ValidateTemplate operation: [/Parameters/InstanceType/Default] 'null' values are not allowed in templates Can you find the error on the template?\n"
},
{
	"uri": "/validate.html",
	"title": "Validating a Template",
	"tags": [],
	"description": "",
	"content": "The InstanceType parameter was missing on the template. Lets make the default a t3.small instance.\nParameters: InstanceType: Default: t3.small Description: WebServer EC2 instance type Type: String To check your template file for syntax errors, we used the aws cloudformation validate-template command.\nThe aws cloudformation validate-template command is designed to check only the syntax of your template. It does not ensure that the property values that you have specified for a resource are valid for that resource. Nor does it determine the number of resources that will exist when the stack is created.\n During validation, AWS CloudFormation first checks if the template is valid JSON. If it isn\u0026rsquo;t, AWS CloudFormation checks if the template is valid YAML. If both checks fail, AWS CloudFormation returns a template validation error. You can validate templates locally by using the --template-body parameter, or remotely with the --template-url parameter.\nTo check the operational validity, you need to attempt to create the stack. There is no sandbox or test area for AWS CloudFormation stacks, so you are charged for the resources you create during testing.\nIf we go back to the CodePipeline console, the execution is stil failing. Let\u0026rsquo;s have a look again at the build logs.\nThis time we got something different:\n------------------------------------------------------------ wordpress/wordpress-single-instance.yaml ------------------------------------------------------------------------------------------------------------------------ | WARN W27 | | Resources: [\u0026quot;WebServerSecurityGroup\u0026quot;] | Line Numbers: [142] | | Security Groups found ingress with port range instead of just a single port Failures count: 0 Warnings count: 1 "
},
{
	"uri": "/cfn-nag.html",
	"title": "Linting a Template",
	"tags": [],
	"description": "",
	"content": "It seems like our security groups are to permissive. Let\u0026rsquo;s make this a bit more restrictive in the CloudFormation Template:\nWebServerSecurityGroup: Type: AWS::EC2::SecurityGroup Properties: GroupDescription: \u0026#34;Enable HTTP access via port 80 locked down to the load balancer + SSH access\u0026#34; VpcId: \u0026#34;default-vpc\u0026#34; SecurityGroupIngress: - CidrIp: 0.0.0.0/0 FromPort: 80 IpProtocol: tcp ToPort: 80 The cfn-nag tool parses a collection of CloudFormation templates and applies rules to find code patterns that could lead to insecure infrastructure. The results of the tool include the logical resource identifiers for violating resources and an explanation of what rule has been violated.\nWhile there are quite a number of particular rules the tool will attempt to match, the rough categories are:\n IAM and resource policies (S3 Bucket, SQS, etc.)  Matches policies that are overly permissive in some way (e.g. wildcards in actions or principals)   Security Group ingress and egress rules  Matches rules that are overly liberal (e.g. an ingress rule open to 0.0.0.0/0, port range 1-65535 is open)   Access Logs  Looks for access logs that are not enabled for applicable resources (e.g. Elastic Load Balancers and CloudFront Distributions)   Encryption  (Server-side) encryption that is not enabled or enforced for applicable resources (e.g. EBS volumes or for PutObject calls on an S3 bucket)    All the rules are considered either warnings or failures. Any discovered failures will result in a non-zero exit code, while warnings will not. In the context of a delivery pipeline, cfn-nag should likely stop the pipeline in the case it finds failures, but perhaps not stop the pipeline in the case of just warnings. Which rules are considered warnings and which are considered errors is a little “loose” or subjective.\nThe cfn-nag tool includes rules that apply universally across environments and enterprises (you can still filter which ones you want to suppress). That said, the product supports the development of custom rules to allow enterprise-specific rules for compliance and security controls.\n However, the execution is still failing. There is one thing left to solve. Can you guess what the problem is?\n2020-04-20 13:21:59.423000+00:00 CREATE_FAILED AWS::EC2::SecurityGroup WebServerSecurityGroup The vpc ID 'default-vpc' does not exist (Service: AmazonEC2; Status Code: 400; Error Code: InvalidVpcID.NotFound; Request ID: eb225981-a162-4555-bf51-4cfe66056c20) "
},
{
	"uri": "/taskcat.html",
	"title": "Testing a Template",
	"tags": [],
	"description": "",
	"content": "We passed our validate stage! The vpc ID default-vpc does not exist. We can leave it out of the security group, as the default works just fine.\nTaskCat is an open source tool developed by the AWS Quick Start team to automate the testing of AWS CloudFormation templates. It tests an AWS CloudFormation template by deploying it in multiple AWS Regions simultaneously and generates a report with a pass/fail result for each Region. You can customize the tests through a test config file. TaskCat is implemented in Python and available as a Docker container and pip module.\nTo run the tests, TaskCat requires a configuration file named taskcat.yml. The taskcat.yml file contains two high-level mappings: global and tests. The global mapping defines the global configurations of the project:\n owner – Project owner’s email address qsname – Name of the project; must be same as the project folder name regions – All the regions where tests need to be executed reporting – To generate test report with logs from each test execution  The tests mapping defines test scenarios that will be performed by TaskCat. You can define multiple test scenarios in the tests mapping, and each test scenario must specify a parameter input file name and an AWS CloudFormation template file name. Optionally, you can define the AWS Regions in which the test needs to be executed. This Region list will override the global Region list. For example, if your AWS CloudFormation template creates AWS resources that are not available in all Regions, you need to override the global Region list and specify only those Regions where those resources are supported.\nproject: name: wordpress-single-instance regions: - eu-west-1 tests: default: template: wordpress/wordpress-single-instance.yaml TaskCat performs multiple actions, such as template validation, parameter validation, and staging content into an Amazon Simple Storage Service (Amazon S3) bucket, before launching the AWS CloudFormation stack. It launches the stack in the defined Regions, simultaneously. And it regularly polls the AWS CloudFormation stack status to check if the stack creation is finished. After the stack has been successfully created, TaskCat deletes it. How much time TaskCat takes to finish the testing depends on how many tests you have defined in your TaskCat configuration file and how long each stack creation and deletion takes. After the TaskCat run is completed, it generates a report in HTML format in the directory from where you are running the TaskCat command.\nTo get the best results when testing your templates with TaskCat, it’s helpful to understand three primary files that TaskCat uses: Standard parameter file, Override parameter files and the configuration file. Take a look at each of these files in more detail, and at how you can use them to create and configure the test cases for your CloudFormation templates.\n "
},
{
	"uri": "/config.html",
	"title": "Enforcing Compliance",
	"tags": [],
	"description": "",
	"content": "The flexible, dynamic nature of the AWS cloud gives developers and admins the flexibility to launch, configure, use, and terminate processing, storage, networking, and other resources as needed. In any fast-paced agile environment, security guidelines and policies can be overlooked in the race to get a new product to market before the competition.\nImagine that you had the ability to verify that existing and newly launched AWS resources conformed to your organization’s security guidelines and best practices without creating a bureaucracy or spending your time manually inspecting cloud resources.\nAWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations. With Config, you can review changes in configurations and relationships between AWS resources, dive into detailed resource configuration histories, and determine your overall compliance against the configurations specified in your internal guidelines. This enables you to simplify compliance auditing, security analysis, change management, and operational troubleshooting.\n AWS Config is designed to help you assess compliance with your internal policies and regulatory standards by providing you visibility into the configuration of your AWS resources as well as third-party resources, and evaluating resource configuration changes against your desired configurations on a continuous basis.\nYou can use AWS Config as your framework for creating and deploying governance and compliance rules across your AWS accounts and regions. You can codify your compliance requirements as AWS Config rules and author remediation actions using AWS Systems Manager Automation documents and package them together within a conformance pack that can be easily deployed across an organization. Therefore, using AWS Config, you can automate assessment of your resource configurations and resource changes to help you ensure continuous compliance and self-governance across your AWS infrastructure.\n"
},
{
	"uri": "/detective.html",
	"title": "Root Cause Analysis",
	"tags": [],
	"description": "",
	"content": "Demanding AWS customers have multiple AWS accounts, collect data from multiple sources, and simple searches based on regular expressions are not enough to conduct in-depth analysis of suspected security-related events. Today, when a security issue is detected, such as compromised credentials or unauthorized access to a resource, security analysts cross-analyze several data logs to understand the root cause of the issue and its impact on the environment. In-depth analysis often requires scripting and ETL to connect the dots between data generated by multiple siloed systems. It requires skilled data engineers to answer basic questions such as “is this normal?”. Analysts use Security Information and Event Management (SIEM) tools, third-party libraries, and data visualization tools to validate, compare, and correlate data to reach their conclusions. To further complicate the matters, new AWS accounts and new applications are constantly introduced, forcing analysts to constantly reestablish baselines of normal behavior, and to understand new patterns of activities every time they evaluate a new security issue.\nAmazon Detective makes it easy to analyze, investigate, and quickly identify the root cause of potential security issues or suspicious activities. Amazon Detective automatically collects log data from your AWS resources and uses machine learning, statistical analysis, and graph theory to build a linked set of data that enables you to easily conduct faster and more efficient security investigations.\n Amazon Detective is a fully managed service that empowers users to automate the heavy lifting involved in processing large quantities of AWS log data to determine the cause and impact of a security issue. Once enabled, Detective automatically begins distilling and organizing data from AWS Guard Duty, AWS CloudTrail, and Amazon Virtual Private Cloud Flow Logs into a graph model that summarizes the resource behaviors and interactions observed across your entire AWS environment.\nAmazon Detective uses machine learning models to produce graphical representations of your account behavior and helps you to answer questions such as “is this an unusual API call for this role?” or “is this spike in traffic from this instance expected?”. You do not need to write code, to configure or to tune your own queries.\n"
},
{
	"uri": "/conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": "Please fill the survey from the below link. \u0026laquo;To-Be-Updated-For-Every-Customer-Engagement\u0026raquo;. Your feedback would be valuable.\n"
},
{
	"uri": "/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]